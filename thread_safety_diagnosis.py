"""
çº¿ç¨‹å®‰å…¨è¯Šæ–­è„šæœ¬
ç”¨äºéªŒè¯æ—¥å¿—ç³»ç»Ÿçš„çº¿ç¨‹å®‰å…¨é—®é¢˜
"""

import threading
import time
import random
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Any
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from logs.core.abstracts import AbstractLogger
from logs.singleton.log_manager import LogManager
from logs.error_handling.error_handler import ErrorHandlingManager, ErrorContext, ErrorSeverity, ErrorCategory
from logs.loggers.async_logger import AsyncLogger
from logs.performance.performance_optimization import BatchProcessor, AsyncBatchProcessor


class ThreadSafetyDiagnostics:
    """çº¿ç¨‹å®‰å…¨è¯Šæ–­å™¨"""
    
    def __init__(self):
        self.diagnostic_results = []
        self.lock = threading.Lock()
        
    def add_diagnostic(self, test_name: str, result: str, details: Dict[str, Any] = None):
        """æ·»åŠ è¯Šæ–­ç»“æœ"""
        with self.lock:
            self.diagnostic_results.append({
                'test_name': test_name,
                'result': result,
                'details': details or {},
                'timestamp': time.time()
            })
    
    def test_lock_initialization_race(self):
        """æµ‹è¯•é”åˆå§‹åŒ–çš„ç«æ€æ¡ä»¶"""
        print("ğŸ” æµ‹è¯•é”åˆå§‹åŒ–ç«æ€æ¡ä»¶...")
        
        race_detected = False
        lock_objects = []
        
        def create_logger_instance():
            nonlocal race_detected
            logger = AbstractLogger("test_logger")
            
            # è®°å½•é”å¯¹è±¡
            if logger._observers_lock is not None:
                lock_objects.append(id(logger._observers_lock))
            
            # æ¨¡æ‹Ÿå¹¶å‘è®¿é—®
            for _ in range(100):
                logger.add_observer(lambda x: None)
                logger.remove_observer(lambda x: None)
        
        # åˆ›å»ºå¤šä¸ªçº¿ç¨‹åŒæ—¶åˆå§‹åŒ–
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [executor.submit(create_logger_instance) for _ in range(10)]
            for future in futures:
                future.result()
        
        # æ£€æŸ¥æ˜¯å¦åˆ›å»ºäº†å¤šä¸ªé”å¯¹è±¡
        unique_locks = set(lock_objects)
        if len(unique_locks) > 1:
            race_detected = True
            print(f"âŒ æ£€æµ‹åˆ°ç«æ€æ¡ä»¶ï¼šåˆ›å»ºäº† {len(unique_locks)} ä¸ªä¸åŒçš„é”å¯¹è±¡")
        else:
            print("âœ… é”åˆå§‹åŒ–ç«æ€æ¡ä»¶æµ‹è¯•é€šè¿‡")
        
        self.add_diagnostic(
            "é”åˆå§‹åŒ–ç«æ€æ¡ä»¶",
            "å¤±è´¥" if race_detected else "é€šè¿‡",
            {"unique_lock_count": len(unique_locks), "total_lock_creations": len(lock_objects)}
        )
    
    def test_deadlock_scenario(self):
        """æµ‹è¯•æ­»é”åœºæ™¯"""
        print("ğŸ” æµ‹è¯•æ­»é”åœºæ™¯...")
        
        deadlock_detected = False
        start_time = time.time()
        
        def simulate_config_update():
            nonlocal deadlock_detected
            try:
                manager = LogManager()
                if not manager.is_initialized():
                    manager.initialize()
                
                # æ¨¡æ‹Ÿé…ç½®æ›´æ–°
                for _ in range(50):
                    manager.update_config(manager.get_config())
                    
            except Exception as e:
                deadlock_detected = True
                print(f"âŒ æ£€æµ‹åˆ°å¯èƒ½çš„æ­»é”: {e}")
        
        def simulate_logger_access():
            nonlocal deadlock_detected
            try:
                manager = LogManager()
                if not manager.is_initialized():
                    manager.initialize()
                
                # æ¨¡æ‹Ÿæ—¥å¿—å™¨è®¿é—®
                for _ in range(50):
                    logger = manager.get_logger(f"test_{random.randint(1, 100)}")
                    
            except Exception as e:
                deadlock_detected = True
                print(f"âŒ æ£€æµ‹åˆ°å¯èƒ½çš„æ­»é”: {e}")
        
        # åˆ›å»ºå¹¶å‘è®¿é—®
        with ThreadPoolExecutor(max_workers=20) as executor:
            config_futures = [executor.submit(simulate_config_update) for _ in range(10)]
            logger_futures = [executor.submit(simulate_logger_access) for _ in range(10)]
            
            all_futures = config_futures + logger_futures
            
            # è®¾ç½®è¶…æ—¶
            try:
                for future in all_futures:
                    future.result(timeout=5.0)  # 5ç§’è¶…æ—¶
            except Exception as e:
                deadlock_detected = True
                print(f"âŒ æ£€æµ‹åˆ°è¶…æ—¶ï¼Œå¯èƒ½å­˜åœ¨æ­»é”: {e}")
        
        elapsed_time = time.time() - start_time
        if not deadlock_detected and elapsed_time > 10.0:
            deadlock_detected = True
            print(f"âŒ æ‰§è¡Œæ—¶é—´è¿‡é•¿ ({elapsed_time:.2f}s)ï¼Œå¯èƒ½å­˜åœ¨æ­»é”")
        elif not deadlock_detected:
            print("âœ… æ­»é”æµ‹è¯•é€šè¿‡")
        
        self.add_diagnostic(
            "æ­»é”åœºæ™¯",
            "å¤±è´¥" if deadlock_detected else "é€šè¿‡",
            {"execution_time": elapsed_time, "timeout_detected": deadlock_detected}
        )
    
    def test_error_recursion(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†é€’å½’"""
        print("ğŸ” æµ‹è¯•é”™è¯¯å¤„ç†é€’å½’...")
        
        recursion_detected = False
        error_manager = ErrorHandlingManager()
        
        def create_recursive_error():
            nonlocal recursion_detected
            
            def error_handler_that_fails(context):
                # è¿™ä¸ªé”™è¯¯å¤„ç†å™¨æœ¬èº«ä¼šå¤±è´¥
                raise Exception("é”™è¯¯å¤„ç†å™¨å¤±è´¥")
            
            # æ·»åŠ ä¼šå¤±è´¥çš„é”™è¯¯å¤„ç†å™¨
            from logs.error_handling.error_handler import ErrorHandler
            class FailingErrorHandler(ErrorHandler):
                def handle_error(self, context):
                    raise Exception("é”™è¯¯å¤„ç†å™¨å¤±è´¥")
            
            error_manager.add_handler(FailingErrorHandler())
            
            try:
                # è§¦å‘é”™è¯¯å¤„ç†
                error_manager.handle_error(
                    Exception("æµ‹è¯•é”™è¯¯"),
                    ErrorSeverity.HIGH,
                    ErrorCategory.UNKNOWN
                )
            except Exception as e:
                if "recursion" in str(e).lower() or "é€’å½’" in str(e):
                    recursion_detected = True
                    print(f"âŒ æ£€æµ‹åˆ°é€’å½’é—®é¢˜: {e}")
        
        create_recursive_error()
        
        if not recursion_detected:
            print("âœ… é”™è¯¯å¤„ç†é€’å½’æµ‹è¯•é€šè¿‡")
        
        self.add_diagnostic(
            "é”™è¯¯å¤„ç†é€’å½’",
            "å¤±è´¥" if recursion_detected else "é€šè¿‡",
            {"recursion_detected": recursion_detected}
        )
    
    def test_async_queue_overflow(self):
        """æµ‹è¯•å¼‚æ­¥é˜Ÿåˆ—æº¢å‡º"""
        print("ğŸ” æµ‹è¯•å¼‚æ­¥é˜Ÿåˆ—æº¢å‡º...")
        
        overflow_detected = False
        dropped_messages = 0
        
        # åˆ›å»ºå°é˜Ÿåˆ—çš„å¼‚æ­¥å¤„ç†å™¨
        from logs.core.interfaces import LogConfig
        from logs.core.types import LogLevel
        
        class MockConfig(LogConfig):
            def get_min_level(self):
                return LogLevel.DEBUG
            
            def get_format_string(self):
                return "%(message)s"
            
            def is_async_enabled(self):
                return True
            
            def get_queue_size(self):
                return 10  # å¾ˆå°çš„é˜Ÿåˆ—
            
            def get_flush_interval(self):
                return 1.0
            
            def get_output_strategies(self):
                return []
        
        async_logger = AsyncLogger("test", MockConfig())
        
        def flood_queue():
            nonlocal dropped_messages
            for i in range(100):
                success = async_logger.log(LogLevel.INFO, f"æµ‹è¯•æ¶ˆæ¯ {i}")
                if not success:
                    dropped_messages += 1
        
        # å¿«é€Ÿ flooding é˜Ÿåˆ—
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(flood_queue) for _ in range(5)]
            for future in futures:
                future.result()
        
        if dropped_messages > 0:
            overflow_detected = True
            print(f"âŒ æ£€æµ‹åˆ°é˜Ÿåˆ—æº¢å‡ºï¼Œä¸¢å¼ƒäº† {dropped_messages} æ¡æ¶ˆæ¯")
        else:
            print("âœ… é˜Ÿåˆ—æº¢å‡ºæµ‹è¯•é€šè¿‡")
        
        self.add_diagnostic(
            "å¼‚æ­¥é˜Ÿåˆ—æº¢å‡º",
            "å¤±è´¥" if overflow_detected else "é€šè¿‡",
            {"dropped_messages": dropped_messages}
        )
    
    def test_performance_bottlenecks(self):
        """æµ‹è¯•æ€§èƒ½ç“¶é¢ˆ"""
        print("ğŸ” æµ‹è¯•æ€§èƒ½ç“¶é¢ˆ...")
        
        performance_issues = []
        
        # æµ‹è¯•æ‰¹é‡å¤„ç†å™¨æ€§èƒ½
        def test_batch_processor():
            start_time = time.time()
            
            def mock_processor(batch):
                time.sleep(0.01)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            
            processor = BatchProcessor(
                batch_size=10,
                max_wait_time=1.0,
                processor=mock_processor
            )
            
            # æ·»åŠ å¤§é‡æ¶ˆæ¯
            for i in range(100):
                from logs.core.types import LogEntry
                from datetime import datetime
                entry = LogEntry(
                    timestamp=datetime.now(),
                    level=None,
                    message=f"æ¶ˆæ¯ {i}",
                    logger_name="test",
                    thread_id=0,
                    exception_info=None,
                    context={}
                )
                processor.add_entry(entry)
            
            # ç­‰å¾…å¤„ç†å®Œæˆ
            processor.flush()
            processor.stop()
            
            elapsed_time = time.time() - start_time
            if elapsed_time > 5.0:  # è¶…è¿‡5ç§’è®¤ä¸ºæ€§èƒ½æœ‰é—®é¢˜
                performance_issues.append(f"æ‰¹é‡å¤„ç†å™¨å¤„ç†æ—¶é—´è¿‡é•¿: {elapsed_time:.2f}s")
        
        test_batch_processor()
        
        if performance_issues:
            print(f"âŒ æ£€æµ‹åˆ°æ€§èƒ½é—®é¢˜: {performance_issues}")
        else:
            print("âœ… æ€§èƒ½æµ‹è¯•é€šè¿‡")
        
        self.add_diagnostic(
            "æ€§èƒ½ç“¶é¢ˆ",
            "å¤±è´¥" if performance_issues else "é€šè¿‡",
            {"issues": performance_issues}
        )
    
    def run_all_diagnostics(self):
        """è¿è¡Œæ‰€æœ‰è¯Šæ–­"""
        print("ğŸš€ å¼€å§‹çº¿ç¨‹å®‰å…¨è¯Šæ–­...")
        print("=" * 50)
        
        self.test_lock_initialization_race()
        print()
        
        self.test_deadlock_scenario()
        print()
        
        self.test_error_recursion()
        print()
        
        self.test_async_queue_overflow()
        print()
        
        self.test_performance_bottlenecks()
        print()
        
        print("=" * 50)
        print("ğŸ“Š è¯Šæ–­ç»“æœæ±‡æ€»:")
        
        failed_tests = [r for r in self.diagnostic_results if r['result'] == 'å¤±è´¥']
        passed_tests = [r for r in self.diagnostic_results if r['result'] == 'é€šè¿‡']
        
        print(f"âœ… é€šè¿‡æµ‹è¯•: {len(passed_tests)}")
        print(f"âŒ å¤±è´¥æµ‹è¯•: {len(failed_tests)}")
        
        if failed_tests:
            print("\nğŸ”´ å¤±è´¥çš„æµ‹è¯•è¯¦æƒ…:")
            for test in failed_tests:
                print(f"  - {test['test_name']}: {test['details']}")
        
        return len(failed_tests) == 0


if __name__ == "__main__":
    diagnostics = ThreadSafetyDiagnostics()
    success = diagnostics.run_all_diagnostics()
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        sys.exit(0)
    else:
        print("\nâš ï¸  å‘ç°é—®é¢˜ï¼Œéœ€è¦ä¿®å¤ï¼")
        sys.exit(1)